---
description: Valida e integra un nuevo portal inmobiliario (E2E)
---

# üöÄ Workflow: Validaci√≥n e Integraci√≥n de Portal

Este flujo automatiza la inclusi√≥n de un nuevo portal desde la investigaci√≥n hasta el despliegue en producci√≥n.

## Fase 1: Investigaci√≥n y Validaci√≥n
1. **Navegaci√≥n:** Acceder a la URL especificada en `nueva-url.md`.
2. **An√°lisis DOM:** Identificar selectores CSS para:
   - Contenedor del card de propiedad.
   - T√≠tulo, Precio, Ubicaci√≥n, √Årea, Habitaciones.
   - Paginaci√≥n (URL param o Click).
3. **Refinamiento:** Actualizar `nueva-url.md` con los selectores exactos y notas t√©cnicas.

## Fase 2: Implementaci√≥n Backend
1. **Crear Scraper:** Generar `backend/scrapers/[nombre].py` heredando de `BaseScraper`.
   - Implementar el m√©todo `async def scrape(self)`.
   - Usar `self.process_property(data)` para cada item.
2. **Registrar en Factory:** 
   - Importar la nueva clase en `backend/scrapers/factory.py`.
   - Agregar el caso correspondiente en `get_scraper` y en `get_all_scrapers`.

## Fase 3: Integraci√≥n Frontend
1. **Actualizar App.jsx:**
   - A√±adir el identificador del portal al array `PORTALS` en `frontend/src/App.jsx` para que aparezca la tarjeta en el dashboard.

## Fase 4: Despliegue (Turbo)
// turbo-all
1. **Commit & Push:**
   - `git add .`
   - `git commit -m "Integraci√≥n completa de portal: [Nombre]"`
   - `git push origin main`
2. **VPS Deployment (v√≠a SSH):**
   - Conectar al VPS: `ssh vps-scraping`
   - Actualizar repo: `cd /root/WebScrapingInmobiliaria && git pull origin main`
   - Reiniciar servicios: `docker compose restart worker backend`

---
**Instrucci√≥n para el Agente:** 
Para ejecutar este flujo, lee la informaci√≥n de `nueva-url.md`. Si un portal tiene el estado ‚è≥ (Pendiente), inicia desde la Fase 1. Si ya tiene ‚úÖ, inicia desde la Fase 2.
